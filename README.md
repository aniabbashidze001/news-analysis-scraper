# ğŸ“° News Analysis Scraper

A modular, multi-source news scraping and analysis system that aggregates articles from major online news platforms, cleans and processes the data, performs trend analysis, and generates insightful reportsâ€”all through a powerful command-line interface (CLI).

## ğŸš€ Project Overview

This project was developed as the final deliverable for the Python Data Scraping course. It is capable of:
- Scraping **over 5000 articles** from multiple sources
- Handling **static**, **dynamic**, and **Scrapy-based** scraping strategies
- Performing data cleaning, validation, and trend analysis
- Exporting data and generating visual HTML reports
- Providing a user-friendly CLI interface
- Supporting scheduled automation and logging

## ğŸ” Features

- âœ… Multi-source scraping:
  - NPR (Static - BeautifulSoup)
  - Euronews (Dynamic - Selenium)
  - The Verge (Scrapy Framework)
- âœ… Support for anti-bot mechanisms:
  - Randomized user-agent headers
  - CAPTCHA detection with screenshot logging
  - Request throttling
- âœ… Configurable and Modular:
  - Easily extendable with new scraping strategies
  - Configurable via `config/settings.yaml`
- âœ… Trend Analysis & Visualization:
  - Article frequency, keyword heatmaps, publishing patterns
- âœ… Database Integration:
  - Uses SQLite to store cleaned and validated articles
- âœ… Clean, documented codebase:
  - Follows design patterns (Factory, Strategy)
  - Includes full docstrings and test suite

## ğŸ› ï¸ Setup & Installation

### Requirements
Install dependencies:

```bash
pip install -r requirements.txt
```

### Configuration

Edit your settings in `config/settings.yaml`.

### Run CLI

```bash
# Interactive menu
python main.py

# Run specific operation
python main.py --export
python main.py --process
python main.py --analyze
python main.py --report
```

## ğŸ“ Project Structure

```
news-analysis-scraper/
â”œâ”€â”€ main.py
â”œâ”€â”€ config/
â”œâ”€â”€ data_output/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ strategies/
â”‚   â”œâ”€â”€ factories/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ templates/
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
```

## ğŸ“Š Results

- **5000+** cleaned articles stored in `news_articles.db`
- Trend charts and summary reports in `data_output/reports/`
- Exports available in CSV, JSON, XLSX

## ğŸ§ª Testing

```bash
# Unit tests
PYTHONPATH=$(pwd) pytest tests/unit/

# Integration tests
PYTHONPATH=$(pwd) pytest tests/integration/
```

## ğŸ‘¥ Team Contributions

- **Ana Abashidze** â€“ CLI design, dynamic scraper, HTML report generation, documentation
- **Elene Topuridze** â€“ Static scraper, data cleaning & analysis, API docs
- **Danieli Iliaevi** â€“ Scrapy crawler, database, testing suite

See full breakdown in [`CONTRIBUTIONS.md`](CONTRIBUTIONS.md)

## ğŸ“„ Documentation

All documentation is located in `/docs`:
- [Architecture](docs/architecture.md)
- [User Guide](docs/user_guide.md)
- [API Reference](docs/api_reference.md)


## ğŸ GitHub Best Practices

- Descriptive commit messages and release tags
- All team members contributed to Git history
- Project follows modular and testable design

---

Made with ğŸ’» and â˜• by Team News Analysis ğŸ”